{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(arrow)\n",
    "library(glmnet)\n",
    "library(caret)\n",
    "library(dplyr)\n",
    "library(precrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(1001)\n",
    "\n",
    "# Load train and validation data set prepared ealier for Python model\n",
    "cases_df <- read_parquet('data/training_data.parquet')\n",
    "cases_df <- select(cases_df, -matches(\"__index_level_0__|case|rf_score\"))\n",
    "cases_df$label <- as.factor(cases_df$label)\n",
    "cases_df$all_p <- as.double(cases_df$all_p)\n",
    "cases_df$all_go <- as.double(cases_df$all_go)\n",
    "\n",
    "validation_df <- read_parquet('data/50_data.parquet')\n",
    "validation_df <- select(validation_df, -matches(\"__index_level_0__|rf_score\"))\n",
    "validation_df$label <- as.factor(validation_df$label)\n",
    "validation_df$all_p <- as.double(validation_df$all_p)\n",
    "validation_df$all_go <- as.double(validation_df$all_go)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes 'tbl_df', 'tbl' and 'data.frame':\t67774 obs. of  11 variables:\n",
      " $ TF      : chr  \"AHR\" \"AHR\" \"AHR\" \"AHR\" ...\n",
      " $ TF_ids  :integer64 196 196 196 196 196 196 196 196 ... \n",
      " $ p_share : num  0.75 0.5 0.5 0.75 0.5 0.5 0.5 1 0.75 0.5 ...\n",
      " $ all_p   : num  4 4 4 4 4 4 4 4 4 4 ...\n",
      " $ p_score : num  5.08 5.99 12.63 4.46 1.77 ...\n",
      " $ go_share: num  0.7 0.7 0.8 0.65 0.7 0.8 0.8 0.75 0.85 0.75 ...\n",
      " $ all_go  : num  20 20 20 20 20 20 20 20 20 20 ...\n",
      " $ go_score: num  164 161 241 170 203 ...\n",
      " $ transfac: num  1.5 1.44 1.13 1.2 1.3 ...\n",
      " $ chea    : num  1.94 1.71 2.01 1.21 1.48 ...\n",
      " $ label   : Factor w/ 2 levels \"0\",\"1\": 1 1 2 1 1 1 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "str(cases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights for each observation in train data\n",
    "neg_w <- 1 - table(cases_df$label)[[1]]/nrow(cases_df)\n",
    "pos_w <- 1 - table(cases_df$label)[[2]]/nrow(cases_df)\n",
    "wgts<- sapply(as.integer(cases_df$label), function(f) ifelse(f==1, neg_w, pos_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>alpha</th><th scope=col>lambda</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>20</th><td>0</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & alpha & lambda\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t20 & 0 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 2\n",
       "\n",
       "| <!--/--> | alpha &lt;dbl&gt; | lambda &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 20 | 0 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "   alpha lambda\n",
       "20 0     1     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grid search for logistic regression model\n",
    "# 'alpha = 0' is used because ridge regularisation worked best in Python version\n",
    "glmnet_grid <- expand.grid(alpha = 0, \n",
    "                           lambda = seq(0, 1, length = 20))\n",
    "\n",
    "glmnet_ctrl <- trainControl(method = \"cv\", number = 5)\n",
    "\n",
    "glmnet_fit <- train(label ~ p_share + all_p + p_score +\n",
    "                                go_share + all_go + go_score + \n",
    "                                transfac + chea,\n",
    "                    data = cases_df, \n",
    "                    method = \"glmnet\", family = 'binomial',\n",
    "                    standardize = TRUE, \n",
    "                    weights = wgts,\n",
    "                    metric = \"Accuracy\",\n",
    "                    maximize = TRUE,\n",
    "                    tuneGrid = glmnet_grid,\n",
    "                    trControl = glmnet_ctrl)\n",
    "\n",
    "# Get best lambda\n",
    "glmnet_fit$bestTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final LR model\n",
    "lr_model <- glmnet(x = as.matrix(cases_df[c('p_share','all_p','p_score',\n",
    "                                            'go_share','all_go','go_score',\n",
    "                                            'transfac','chea')]), \n",
    "                   y = cases_df$label,\n",
    "                   family = 'binomial',\n",
    "                   alpha = 0,\n",
    "                   nlambda = 1,\n",
    "                   lambda = 1,\n",
    "                   standardize = TRUE,\n",
    "                   weights = wgts\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take 1000 samples from validation data set to average ROC and PR curves\n",
    "n = 1000\n",
    "frac = 0.8\n",
    "total_pred <- data.frame(label = c(), prob = c(), num = c())\n",
    "for (i in 1:n){\n",
    "    sample_rows <- sample(1:nrow(validation_df), floor(frac*nrow(validation_df)), replace = FALSE)\n",
    "    lr_pred <- predict(lr_model,\n",
    "                       as.matrix(validation_df[sample_rows,\n",
    "                                               c('p_share','all_p','p_score',\n",
    "                                                 'go_share','all_go','go_score',\n",
    "                                                 'transfac','chea')]), \n",
    "                       type=\"response\")\n",
    "    total_pred <- rbind(total_pred, \n",
    "                        data.frame(label = validation_df[sample_rows, 'label'],\n",
    "                                   prob = as.vector(lr_pred),\n",
    "                                   num = i))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'ROC AUC = 0.864428770898652'"
      ],
      "text/latex": [
       "'ROC AUC = 0.864428770898652'"
      ],
      "text/markdown": [
       "'ROC AUC = 0.864428770898652'"
      ],
      "text/plain": [
       "[1] \"ROC AUC = 0.864428770898652\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'PR AUC = 0.84582274762439'"
      ],
      "text/latex": [
       "'PR AUC = 0.84582274762439'"
      ],
      "text/markdown": [
       "'PR AUC = 0.84582274762439'"
      ],
      "text/plain": [
       "[1] \"PR AUC = 0.84582274762439\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAFoCAMAAAC8KnXeAAAAQlBMVEUAAAAzMzNNTU1oaGh8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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downsample predictions to get PR curve which can be compared to other models/TF libraries\n",
    "downsampled_pred <- downSample(total_pred, total_pred$label)\n",
    "\n",
    "# Prepare data for plotting\n",
    "perf_data <- mmdata(split(downsampled_pred[[\"prob\"]], downsampled_pred[[\"num\"]]),\n",
    "                    split(downsampled_pred[[\"label\"]], downsampled_pred[[\"num\"]]),\n",
    "                    dsids = (c(1:n)))\n",
    "\n",
    "# Calculate curves for multiple test datasets and keep all the curves\n",
    "perf_curves <- evalmod(perf_data, raw_curves = TRUE)\n",
    "\n",
    "# Show curves with the 95% confidence bounds\n",
    "paste0('ROC AUC = ', as.data.frame(evalmod(scores = total_pred$prob, labels = total_pred$label, mode = 'aucroc'))[1,3])\n",
    "paste0('PR AUC = ', auc(evalmod(scores = downsampled_pred$prob, label = as.integer(downsampled_pred$label)))[2,4])\n",
    "options(repr.plot.width = 5, repr.plot.height = 3)\n",
    "autoplot(perf_curves, show_cb = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LR model\n",
    "save(lr_model, file = 'data/log_mod.RData')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
